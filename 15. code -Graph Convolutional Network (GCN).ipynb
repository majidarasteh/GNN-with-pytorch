{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f719bb-b5b8-4893-8fbb-a1428c6d70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here's a simple implementation of a Graph Convolutional Network (GCN) using PyTorch Geometric (PyG) for node classification.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c40169-dd32-49d3-a2a9-b90c6f0e3e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "065e5194-e041-4161-9008-8a1a579cb022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "# 1. Download and preprocess data\n",
    "\n",
    "# Device Configuration - Purpose: Use GPU if available for faster training.\n",
    "\"\"\"\n",
    "   torch.cuda.is_available(): Checks if CUDA-enabled GPU is available\n",
    "   device variable: Will be either 'cuda' (GPU) or 'cpu' (CPU)\n",
    "\"\"\"\n",
    "\n",
    "device  = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "# Load Cora dataset with normalized features\n",
    "\"\"\"\n",
    "     root: Directory where dataset will be stored/downloaded\n",
    "     name='Cora': Specifies the Cora dataset (citation network)\n",
    "     transform=NormalizeFeatures(): Applies feature normalization\n",
    "\n",
    "    dataset[0]: Accesses the first (and only) graph in the dataset\n",
    "    .to(device): Moves all tensors (features, edges, etc.) to GPU/CPU\n",
    "\"\"\"\n",
    "dataset = Planetoid(root='C:/Users/Majid/Downloads/CNN', name='Cora', transform=NormalizeFeatures())\n",
    "data = dataset[0].to(device)  # Move graph data to GPU/CPU\n",
    "    \n",
    "  \n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3416157a-40b3-4a21-9152-7465250297cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define a 2-layer GCN model\n",
    "\n",
    "# Inherits from PyTorch's Module base class (required for all neural networks in PyTorch).\n",
    "class GCN(torch.nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "       Constructor (__init__)\n",
    "       Defines the model's architecture. Takes 3 arguments:\n",
    "         * num_features: Input feature dimension (e.g., 1433 for Cora dataset).\n",
    "         * hidden_dim: Size of the hidden layer (e.g., 16).\n",
    "         * num_classes: Number of output classes (e.g., 7 for Cora).  \n",
    "\n",
    "          super().__init__()   Initializes the parent class (torch.nn.Module).\n",
    "          conv1: Defines the first GCN layer:\n",
    "                   - Input: num_features (e.g., 1433).\n",
    "                   - Output: hidden_dim (e.g., 16).\n",
    "                 Performs neighborhood aggregation + linear transformation.\n",
    "\n",
    "          conv2: Defines the second GCN layer:\n",
    "                    - Input: hidden_dim (e.g., 16).\n",
    "                    - Output: num_classes (e.g., 7).\n",
    "                  Maps hidden features to class logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)  # Layer 1\n",
    "        self.conv2 = GCNConv(hidden_dim, num_classes)   # Layer 2\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Defines how data flows through the network. Takes:\n",
    "           - x: Node feature matrix (shape: [num_nodes, num_features]).\n",
    "           - edge_index: Graph connectivity (shape: [2, num_edges]).\n",
    "    \"\"\"\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "            Applies the first GCN layer:\n",
    "              - Aggregates features from 1-hop neighbors.\n",
    "              - Transforms features to hidden_dim space.\n",
    "              \n",
    "        \"\"\"\n",
    "        x = self.conv1(x, edge_index)             # First GCN layer (with ReLU activation)    \n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "            Applies ReLU activation (introduces nonlinearity):\n",
    "              - ReLU(x) = max(0, x).\n",
    "              - Helps the model learn complex patterns.\n",
    "        \"\"\"\n",
    "        x = F.relu(x)    \n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "            Applies dropout (regularization):\n",
    "              - Randomly zeros some activations during training (self.training=True).\n",
    "              - Prevents overfitting (default dropout rate: 0.5 in PyG).\n",
    "        \"\"\"\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "             Second GCN layer (output logits):\n",
    "              - Further aggregates features.\n",
    "              - Maps to num_classes-dimensional output (logits).\n",
    "        \"\"\"\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        \"\"\"\n",
    "           Applies log-softmax to logits:\n",
    "             - Normalizes outputs to log-probabilities.\n",
    "             - dim=1 ensures normalization across classes for each node.\n",
    "        \"\"\"\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8021b3bf-9ad4-4cbb-a705-65a5622c8da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initialize model\n",
    "model = GCN(\n",
    "    num_features=dataset.num_features,  # Input feature dimension\n",
    "    hidden_dim=16,                      # Hidden layer dimension\n",
    "    num_classes=dataset.num_classes     # Number of classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f3d1e1-1f49-4d63-8550-01da7082851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train the model\n",
    "\n",
    "\"\"\"\n",
    "   optimizer: Adam optimizer with:\n",
    "   Learning rate (lr=0.1) \n",
    "   Weight decay (5e-4) - L2 regularization to prevent overfitting\n",
    "   criterion: CrossEntropyLoss - Standard for multi-class classification\n",
    "\"\"\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    # # Sets model to training mode (important for dropout/batch norm if used)\n",
    "    model.train()\n",
    "\n",
    "    # # Resets gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calls the forward method of SGCModel\n",
    "    # Input: Node features (data.x) and graph structure (data.edge_index)\n",
    "    # Output: Class predictions for all nodes\n",
    "    out = model(data.x, data.edge_index)\n",
    "\n",
    "    # calculates the loss during training using Negative Log Likelihood (NLL) loss.\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "    # Computes gradients via backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Updates model parameters using gradients\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b9d278a-a4b8-41c7-80f8-dc4d9c872e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Test the model\n",
    "def test():\n",
    "    # Puts the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Runs the forward pass of the model\n",
    "    out = model(data.x, data.edge_index)\n",
    "\n",
    "    # Converts logits to predicted class labels\n",
    "    pred = out.argmax(dim=1)\n",
    "    \n",
    "    # Sums correct predictions (train_correct.sum())\n",
    "    correct = pred[data.test_mask] == data.y[data.test_mask]\n",
    "    acc = int(correct.sum()) / int(data.test_mask.sum())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23e4f1cc-6e68-4585-93d3-558d54cd3e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 1.9461, Test Acc: 0.1660\n",
      "Epoch: 010, Loss: 1.8756, Test Acc: 0.7310\n",
      "Epoch: 020, Loss: 1.7443, Test Acc: 0.7360\n",
      "Epoch: 030, Loss: 1.5688, Test Acc: 0.7530\n",
      "Epoch: 040, Loss: 1.3929, Test Acc: 0.8010\n",
      "Epoch: 050, Loss: 1.1163, Test Acc: 0.7990\n",
      "Epoch: 060, Loss: 1.0112, Test Acc: 0.8070\n",
      "Epoch: 070, Loss: 0.7930, Test Acc: 0.7980\n",
      "Epoch: 080, Loss: 0.6705, Test Acc: 0.8110\n",
      "Epoch: 090, Loss: 0.6110, Test Acc: 0.8160\n",
      "Epoch: 100, Loss: 0.5652, Test Acc: 0.8190\n",
      "Epoch: 110, Loss: 0.5136, Test Acc: 0.8180\n",
      "Epoch: 120, Loss: 0.4931, Test Acc: 0.8070\n",
      "Epoch: 130, Loss: 0.4213, Test Acc: 0.8120\n",
      "Epoch: 140, Loss: 0.4247, Test Acc: 0.8090\n",
      "Epoch: 150, Loss: 0.3609, Test Acc: 0.8020\n",
      "Epoch: 160, Loss: 0.3217, Test Acc: 0.8160\n",
      "Epoch: 170, Loss: 0.3889, Test Acc: 0.8060\n",
      "Epoch: 180, Loss: 0.3230, Test Acc: 0.8090\n",
      "Epoch: 190, Loss: 0.3307, Test Acc: 0.8090\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        acc = test()\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
