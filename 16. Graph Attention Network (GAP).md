# Graph Attention Network (GAT) 
**Graph Attention Network (GAT)** was introduced by Petar Veličković et al. in 2017. GAT introduces attention mechanisms to graph neural networks, allowing nodes to dynamically weigh the importance of their neighbors during feature aggregation. Unlike GCNs (which treat all neighbors equally), GAT learns to focus on relevant connections. Graph Attention Networks (GATs) indeed lies in the attention weight $α_{ij}$, which dynamically quantifies the importance of node $j's$ features to node $i$. For example, in a social network, your close friends’ opinions might matter more than distant connections.

## Definition of $α_{ij}$ in GAT
The attention weight $α_{ij}$ is computed in three steps:  
1. **Linear Transformation**  
   In Graph Attention Networks (GAT), the node features $h_i$ and $h_j$ are numerical vectors that represent the characteristics or attributes of nodes $i$ and $j$ in a graph. These features are the input data for the GAT model and are used to compute attention weights ($α_{ij}$). Their shapes is $F$, where $F$ = feature dimension. For example, in a social network, features could include: user profile data such as age and interests, activity metrics such as enumber of posts and likes.  In a citation network (like Cora dataset) features could include: Bag-of-words representation of a paper’s text and Metadata such as publication year.

   ![image](https://github.com/user-attachments/assets/08199dc5-6388-4834-8372-5efdd83c8c93)

   In Graph Attention Networks (GAT), $Wh_i$ and $Wh_j$ are transformed node features, created by multiplying the original features ($h_i$ and $h_j$) with a learnable weight matrix W. This projects features into a higher-level space ($F′$ dimensions).  $Wh_i$ and $Wh_j$ Allow the model to learn which features are important for attention. Therefore:

   ![image](https://github.com/user-attachments/assets/0b658328-85c5-490c-9610-6922ca18dbc2)

2.  **Attention Score** $e_{ij}$:  
   In Graph Attention Networks (GAT), the vector $a$ (often called the "learnable attention vector") is a critical component that determines how much importance (attention) node $i$ should assign to its neighbor $j$. It acts like a "scorer" that evaluates the compatibility between two nodes. For example:  

    ![image](https://github.com/user-attachments/assets/dc172806-879e-4bbc-b2ec-b64ee20476a4)  

    The $a$ allows the model to focus on relevant neighbors dynamically (unlike GCN’s fixed weights) and Computes the unnormalized attention score $e_{ij}$ between node $i$ and its neighbor $j$.

    ![image](https://github.com/user-attachments/assets/4968fcd2-994f-4811-9d8c-53b7369b3754)

4. **Normalization with Softmax:**
   Scores are normalized over node $i$’s neighborhood $N_i$ using softmax:

      ![image](https://github.com/user-attachments/assets/34a84016-4d17-4593-bdba-427ce4fe4fb4)

    So we have:  
    ![image](https://github.com/user-attachments/assets/d39d7726-517f-47ac-8d0a-efcbfd2a6ff7)


5. **Key Formula:**  
   This defines how GAT dynamically prioritizes neighbors.

   ![image](https://github.com/user-attachments/assets/389b2be5-76ad-4fb8-ba42-e8631b07ac87)


## Step-by-Step Numerical Example
  
  
