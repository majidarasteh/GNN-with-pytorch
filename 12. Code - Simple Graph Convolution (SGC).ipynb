{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa24f9d-6acd-4e60-a2c2-bf4c952f02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid           # Downloads standard citation network datasets (Cora, Citeseer, Pubmed)\n",
    "from torch_geometric.transforms import NormalizeFeatures # Normalizes node features to sum to 1 (helps training)\n",
    "from torch_geometric.nn import SGConv\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704825ab-84a2-49de-9300-0a180c123c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora()\n",
      "First 5 nodes features : tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "\n",
      "First 5 edges: tensor([[ 633, 1862, 2582,  ...,  598, 1473, 2706],\n",
      "        [   0,    0,    0,  ..., 2707, 2707, 2707]])\n",
      "\n",
      "First 5 labels: tensor([3, 4, 4, 0, 3])\n",
      "\n",
      "First 5 test mask: tensor([False, False, False, False, False])\n",
      "First 5 train mask: tensor([True, True, True, True, True])\n",
      "First 5 validation mask: tensor([False, False, False, False, False])\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    data: The complete graph object containing:\\n       - Node features (data.x)\\n       - Edge indices (data.edge_index)\\n       - Labels (data.y)\\n       - Train/val/test masks (data.train_mask, etc.)\\n    dataset.num_features: Number of input features per node (1,433)\\n    dataset.num_classes: Number of output classes (7)\\n '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Download and preprocess data\n",
    "\n",
    "# Device Configuration - Purpose: Use GPU if available for faster training.\n",
    "\"\"\"\n",
    "   torch.cuda.is_available(): Checks if CUDA-enabled GPU is available\n",
    "   device variable: Will be either 'cuda' (GPU) or 'cpu' (CPU)\n",
    "\"\"\"\n",
    "\n",
    "device  = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "# Load Cora dataset with normalized features\n",
    "\"\"\"\n",
    "     root: Directory where dataset will be stored/downloaded\n",
    "     name='Cora': Specifies the Cora dataset (citation network)\n",
    "     transform=NormalizeFeatures(): Applies feature normalization\n",
    "\n",
    "    dataset[0]: Accesses the first (and only) graph in the dataset\n",
    "    .to(device): Moves all tensors (features, edges, etc.) to GPU/CPU\n",
    "\"\"\"\n",
    "dataset = Planetoid(root='C:/Users/Majid/Downloads/CNN', name='Cora', transform=NormalizeFeatures())\n",
    "data = dataset[0].to(device)  # Move graph data to GPU/CPU\n",
    "    \n",
    "# Print dataset info\n",
    "print(f\"Dataset: {dataset}\")\n",
    "print(f\"First 5 nodes features : {data.x[:5]}\\n\")\n",
    "print(f\"First 5 edges: {data.edge_index[:5]}\\n\")\n",
    "print(f\"First 5 labels: {data.y[:5]}\\n\")\n",
    "print(f\"First 5 test mask: {data.test_mask[:5]}\")\n",
    "print(f\"First 5 train mask: {data.train_mask[:5]}\")\n",
    "print(f\"First 5 validation mask: {data.val_mask[:5]}\")\n",
    "   \n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "\n",
    "\"\"\"\n",
    "    data: The complete graph object containing:\n",
    "       - Node features (data.x)\n",
    "       - Edge indices (data.edge_index)\n",
    "       - Labels (data.y)\n",
    "       - Train/val/test masks (data.train_mask, etc.)\n",
    "    dataset.num_features: Number of input features per node (1,433)\n",
    "    dataset.num_classes: Number of output classes (7)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6a35fa-4b49-46b8-b597-387a6be89aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build Model\n",
    "\n",
    "\"\"\"\n",
    "    * Class Definition:\n",
    "        - Inherits from nn.Module (base class for all PyTorch neural networks)\n",
    "        - This inheritance provides essential functionality for model training and saving\n",
    "        \n",
    "    * __init__ Method (Initialization):\n",
    "        - num_features: Dimension of input features per node (1433 for Cora)\n",
    "        - num_classes: Number of output classes (7 for Cora)\n",
    "        - K=2: Number of hops/propagation steps (default=2)\n",
    "        - super().__init__(): Initializes the parent nn.Module class\n",
    "        - self.conv: Creates the SGC layer using PyG's SGConv\n",
    "\n",
    "    * SGConv Layer:\n",
    "        - Performs two key operations:\n",
    "            * Feature Propagation: Smooths features over K-hop neighborhoods\n",
    "            * Linear Transformation: Applies learned weights W\n",
    "        - Combines these into single efficient operation\n",
    "        - No nonlinear activation between steps (unlike traditional GCNs)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SGCModel(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, K=2):\n",
    "        super().__init__()\n",
    "        self.conv = SGConv(num_features, num_classes, K=K)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        forward Method:\n",
    "            - Defines how data flows through the network\n",
    "            - Parameters:\n",
    "                * x: Node feature matrix (shape: [num_nodes, num_features])\n",
    "                * edge_index: Graph connectivity (shape: [2, num_edges])\n",
    "                \n",
    "            - Simply passes these through the SGC layer\n",
    "            - Output: logits for each node (shape: [num_nodes, num_classes])\n",
    "\n",
    "            - Key Characteristics of This Model: \n",
    "                Only one learnable layer (the SGConv)\n",
    "                No hidden layers or nonlinear activations\n",
    "\n",
    "            K=2 means the model considers 2-hop neighborhoods\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        return self.conv(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eca16d8-d44c-4fab-82df-73566d36e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "\n",
    "# Creates a new instance of our SGCModel class\n",
    "model = SGCModel(\n",
    "    num_features=dataset.num_features, # Sets the input dimension to match the dataset's feature size. For Cora dataset: 1433 \n",
    "    num_classes=dataset.num_classes,   # Sets output dimension to number of target classes. For Cora labels: 7 \n",
    "    K=2  # Number of propagation hops. K=2 means the model considers 2-hop neighborhoods\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9bf029-e8c8-4fe7-a15d-e0802bc3bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fitting and embedding\n",
    "\n",
    "\"\"\"\n",
    "   optimizer: Adam optimizer with:\n",
    "   Learning rate (lr=0.2) - Higher than typical (0.001) because SGC trains fast\n",
    "   Weight decay (5e-4) - L2 regularization to prevent overfitting\n",
    "   criterion: CrossEntropyLoss - Standard for multi-class classification\n",
    "\"\"\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.2, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    # Sets model to training mode (important for dropout/batch norm if used)\n",
    "    model.train()    \n",
    "\n",
    "    # Resets gradients from previous iteration\n",
    "    optimizer.zero_grad()   \n",
    "    \n",
    "    # Calls the forward method of SGCModel\n",
    "    # Input: Node features (data.x) and graph structure (data.edge_index)\n",
    "    # Output: Class predictions for all nodes\n",
    "    out = model(data.x, data.edge_index)\n",
    "\n",
    "    #  Computed only on training nodes (data.train_mask)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "    # Computes gradients via backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Updates model parameters using gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9471a7c-c3c7-469e-86bb-30cc1de06e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Prediction and evaluation\n",
    "def test():\n",
    "\n",
    "    \"\"\" Puts the model in evaluation mode\n",
    "        Disables dropout and batch normalization layers if present\n",
    "        Ensures consistent behavior during inference\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    \"\"\" Runs the forward pass of the model\n",
    "        Inputs: \n",
    "             data.x: Node feature matrix (shape: [num_nodes, num_features]) \n",
    "             data.edge_index: Graph connectivity (shape: [2, num_edges])\n",
    "        data.edge_index: Graph connectivity (shape: [2, num_edges])\n",
    "    \"\"\"\n",
    "    out = model(data.x, data.edge_index)\n",
    "\n",
    "    \"\"\"\n",
    "       Converts logits to predicted class labels\n",
    "       argmax(dim=1) selects the class with highest score for each node\n",
    "       Result is a tensor of predicted class indices (shape: [num_nodes])\n",
    "    \"\"\"\n",
    "    pred = out.argmax(dim=1)\n",
    "    \n",
    "    # Accuracy Calculation\n",
    "    \"\"\"\n",
    "       Sums correct predictions (train_correct.sum())\n",
    "       Divides by total nodes in split (train_mask.sum())\n",
    "       Converts to Python int to avoid tensor types\n",
    "       Results are floating-point accuracy values between 0 and 1\n",
    "    \"\"\"\n",
    "    train_correct = pred[data.train_mask] == data.y[data.train_mask]\n",
    "    val_correct = pred[data.val_mask] == data.y[data.val_mask]\n",
    "    test_correct = pred[data.test_mask] == data.y[data.test_mask]\n",
    "    \n",
    "    train_acc = int(train_correct.sum()) / int(data.train_mask.sum())\n",
    "    val_acc = int(val_correct.sum()) / int(data.val_mask.sum())\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n",
    "    \n",
    "    return train_acc, val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2c5e07-8328-4b47-95ef-5ae00875a4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 1.9466, Train: 0.4286, Val: 0.3040, Test: 0.2850\n",
      "Epoch: 010, Loss: 1.5314, Train: 0.9357, Val: 0.7780, Test: 0.8000\n",
      "Epoch: 020, Loss: 1.5047, Train: 0.9214, Val: 0.7740, Test: 0.7860\n",
      "Epoch: 030, Loss: 1.4927, Train: 0.9214, Val: 0.7580, Test: 0.7610\n",
      "Epoch: 040, Loss: 1.4923, Train: 0.9143, Val: 0.7580, Test: 0.7710\n",
      "Epoch: 050, Loss: 1.4962, Train: 0.9143, Val: 0.7720, Test: 0.7830\n",
      "Epoch: 060, Loss: 1.4984, Train: 0.9143, Val: 0.7740, Test: 0.7770\n",
      "Epoch: 070, Loss: 1.4986, Train: 0.9143, Val: 0.7740, Test: 0.7800\n",
      "Epoch: 080, Loss: 1.4990, Train: 0.9143, Val: 0.7720, Test: 0.7800\n",
      "Epoch: 090, Loss: 1.4986, Train: 0.9143, Val: 0.7720, Test: 0.7800\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "# Runs for 100 complete passes through the dataset\n",
    "for epoch in range(100):\n",
    "\n",
    "    \"\"\"\n",
    "       Call train() function:\n",
    "           Sets model to training mode (model.train())\n",
    "           Performs forward pass to compute predictions\n",
    "           Calculates loss on training nodes\n",
    "           Calculates loss on training nodes\n",
    "           Updates model parameters (optimizer.step())\n",
    "           Updates model parameters (optimizer.step())\n",
    "    \"\"\"\n",
    "    loss = train()\n",
    "\n",
    "    \"\"\"\n",
    "        Calls test() function which:\n",
    "            Sets model to evaluation mode (model.eval())\n",
    "            Computes predictions on all data\n",
    "            Computes predictions on all data\n",
    "            \n",
    "    \"\"\"\n",
    "    if epoch % 10 == 0:\n",
    "        train_acc, val_acc, test_acc = test()\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25cec944-f1d1-4f28-b677-79818a67e80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results: Train: 0.9143, Val: 0.7720, Test: 0.7800\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "train_acc, val_acc, test_acc = test()\n",
    "print(f'Final results: Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
